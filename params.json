{"name":"Graph-explorer","tagline":"A graphite dashboard unlike any other","body":"# Graph explorer\r\n\r\nA highly interactive dashboard to satisfy varying ad-hoc information needs across a multitude of metrics by using plugins which\r\n\r\n* add metadata to individual graphite metrics, (tags such as as server, service, type, ...)\r\n* define how to generate (multiple) targets for any metric (to render as a count, a rate, etc)\r\n\r\nyou can then use expressive queries which leverage this metadata to filter targets and group them into graphs in arbitrary ways.\r\nSomething like SQL but targets for rows and a list of graph definitions as a result set.\r\nThe graphs themselves support annotated events and are also interactive because it uses [timeserieswidget](https://github.com/vimeo/timeserieswidget)\r\n\r\nQuick example videos which are dated but give you an idea:\r\n\r\n* [diskspace example (1:20)](https://vimeo.com/54906914)\r\n* [openstack swift example (1:57)](https://vimeo.com/54912886)\r\n\r\nFurthermore, the code is simple and hackable (just a few hundred sLOC), uses simple python files as plugins, and is a breeze to get running (only external dep. is python)\r\n\r\n![Screenshot](https://raw.github.com/vimeo/graph-explorer/master/screenshot.png)\r\n\r\n## Enhanced Metrics\r\n\r\nIn graphite, a metric has a name and a corresponding time series of values.\r\nGraph-explorer's plugins define rules which match metric names, parse them and yield a target with associated metadata:\r\n\r\n* tags from fields in the metric name (server, service, interface_name, etc) by using named groups in a regex.  (there's some guidelines for tags, see below)\r\n* target_type (count, rate, gauge, ...)\r\n* plugin (i.e. 'cpu')\r\n* the graphite target (often just the metric name, but you can use the [graphite functions](http://graphite.readthedocs.org/en/1.0/functions.html) like `derivative`, `scale()` etc.\r\n\r\nall metadata is made available as a tag, and an id is generated from all tag keys and values, to provide easy matching.\r\n\r\nthe configuration also provide settings:\r\n\r\n* `configure` function or list of functions to further enhance the target dynamically (given the match object and the target along with its config), in addition to the default\r\n  defined function which can also be overridden.\r\n\r\nNote that it is trivial to yield multiple targets from the same metric.  I.e. you can have a metric available as rate, counter, average, etc by applying different functions.\r\n\r\nTry to use standardized nomenclature in target types and tags.  Do pretty much what statsd does:\r\n\r\n* rate: a number per second\r\n* count: a number per a given interval (such as a statsd flushInterval)\r\n* gauge: values at each point in time\r\n* counter: a number that keeps increasing over time (but might wrap/reset at some points) (no statsd counterpart) (you'll probably also want to yield this as a rate with `derivative()`)\r\n* timing: TBD\r\n\r\nother words you might use are `pct` (percent), `http_method`, `device`, etc.  Also, keep everything in lowercase, that just keeps things easy when matching.\r\nSome exceptions for things that are accepted to be upper case are http methods (GET, PUT,etc)\r\n\r\ntag definitions:\r\n\"what\": the intrinsic thing that we're graphing (not *how* we graph it). i.e. errors, requests, cpu_state (used in vtitle, grouping into graphs)\r\n\"type\": extra info. i.e. if what is errors, this can be 'in'. if what is requests, this can be '404'. sometimes you may want to put multiple words here, and that's ok (but consider creating new tags for those)\r\n\"wt\": often a metric path will contain one key that has info on both the \"what\" and \"type\", \"wt\" is commonly used to catch it, so you can sanitize it (see below)\r\n\r\nall metrics must have a 'target_type' and a 'what'. because otherwise they are meaningless, also because they are used in the default group_by (TODO: show warnings if not)\r\n\r\nsanitization\r\nthe process of properly setting \"what\" and \"type\" tags from a \"wt\" tag and deleting the \"wt\" tag again.\r\n\r\n## Graphs\r\n\r\n* Are built as requested by your query.\r\n* Plugins can yield graphs directly, they specify targets either as graphite strings or as config dict.  To be revised.  leverage enhanced targets?  Not sure how this will fit in\r\n  as I'm aiming to make it possible to match metrics in a lightweight way and compose graphs ad-hoc with minimal fuss.  \r\n  Note that graphs are matched in the same way targets are (based on their id, tags, etc)\r\n  At this time only one example: in the statsd plugin\r\n\r\n\r\n## Query parsing and execution\r\n\r\nthe Graphite Query Language is a language designed to:\r\n\r\n* let you compose graphs from metrics in a flexible way.\r\n  you can use tags and pattern matching to filter and group targets (from different plugins) into the same or nearby graphs for easy comparison and correlation across seamingly different aspects.\r\n  you can compare metrics, the rate at which the metrics change, etc.\r\n* get in your way as little as possible (loose syntax that's easy to start with but provides powerfull features)\r\n\r\n\r\n## the algorithm\r\n\r\n* from the query input you provide...\r\n* parse out any special statements (see below)\r\n* split up result into separate patterns (white space as boundary), each of which must match on its own.\r\n* you can use `!` to negate\r\n* any pattern that has `:` or `=` inside it matches on tags, like so:\r\n  * `=<val>`      : a tag must have value `<val>`\r\n  * `<key>=`      : a tag with key `<key>` must exist\r\n  * `<key>=<val>` : a tag with key `<key>` must exist and have value `<val>`\r\n  * `:<val>`      : a tag with value matching regex `<val>` must exist\r\n  * `<key>:`      : a tag with key matching regex `<key>` must exist\r\n  * `<key>:<val>` : a tag with key `<key>` must exist and its value must match the regex `<val>`\r\n* any other pattern is treated as a regular expression, which must match the target name.\r\n* matching targets are collected, grouped into graphs and rendered\r\n\r\nnote:\r\n\r\n* order between patterns is irrelevant\r\n* tag matching for 'target_type' and 'what' tags are not performed on graph objects, because they don't apply for them.\r\n\r\n## special predicates\r\n\r\nUnless mentioned otherwise, these statements are all optional (i.e. have default values), can occur anywhere within the query and\r\nthe values must not contain white space.\r\n\r\n### `graph|list `\r\n\r\ndefault: graph  \r\nthis statement goes in the beginning of the query.\r\n\r\n* graph (default): builds and shows the graphs from your input\r\n* list: shows all matching targets (not the matching graphs)\r\n\r\n\r\n### group by `<tagspec>` and GROUP BY `<tagspec>`\r\n\r\n`<tagspec>` is a list like so: `foo[=][,bar[=][,baz[=][...]]]`\r\nbasically a comma-separated list of tags with optional '=' suffix to denote soft or hard (see below).\r\n\r\nby default, grouping is by `target_type=`, `what=` and `server`.\r\nThe tags `target_type` and `what` are strong, meaning a `<tag>=` pattern is added to the query so that only targets are shown that have the tag.\r\nThe tag `server` is soft so that no pattern is added, and targets without this tag will show up too.\r\n\r\nYou can affect this in two ways:\r\n* specify `group by <tagspec>` to keep the standard hard tags and replace all soft tags with `foo`, `bar`, etc.\r\n* specify `GROUP BY <tagspec>` to replace the original list entirely and only group by `foo`, `bar`, etc.\r\n\r\nFor example, the cpu plugin yields targets with tags:\r\n\r\n* target_type: gauge_pct (all of them)\r\n* what: cpu_state (all of them)\r\n* type : something like iowait\r\n* server: the host name\r\n* core: core name (core0, etc)\r\n\r\n* default: grouping by `target_type=`, `what=` and `server`.  So you get a graph for each server, showing the different types for all different cores.\r\n* `group by type` shows for each type (iowait, idle, etc) a graph comparing all cores on all servers\r\n* `group by core,server` shows a graph for each core on each server.\r\n\r\n(a good way to try this out would be to query for `cpu_state` and maybe filter on servername so you only get a few hostnames)\r\n(no effect in 'list' mode)\r\n\r\n\r\n### sum by `<tagspec>`\r\n\r\n`<tagspec>` is a list like so: `foo[,bar][...]`\r\n\r\ncauses all the targets on every graph to be summed together by these tags, and shown as one.  if their other tags have the same values.\r\n(no effect in 'list' mode)\r\n\r\n\r\n### from `<word>`\r\n\r\ndefault: '-24hours'.  \r\naccepts anything [graphite accepts](http://graphite.readthedocs.org/en/1.0/url-api.html#from-until) which is a whole lot\r\n(no effect in 'list' mode)\r\n\r\n### to `<word>`\r\n\r\ndefault: 'now'.  \r\naccepts anything graphite accepts (see above)\r\n(no effect in 'list' mode)\r\n\r\n\r\n### limit `<number>`\r\n\r\ndefault: 500\r\nlimit returned targets (to avoid killing you browser and/or graphite server). 0 means no limit\r\n(no effect in 'list' mode)\r\n\r\n## Examples\r\n\r\n* `cpu`: all cpu graphs (for all machines)\r\n* `web cpu`: cpu graphs for all servers matching 'web'. (grouped by server by default)\r\n* `web cpu total.(system|idle|user|iowait)`: restrict to some common cpu metrics\r\n* `web cpu total.(system|idle|user|iowait) group by type`: same, but compare matching servers on a graph for each cpu metric\r\n* `web123`: all graphs of web123\r\n* `server[1-5] (mem|cpu)`: memory and cpu graphs of servers 1 through 5\r\n* `!server[1-5] (mem|cpu) from 20091201 to 20091231`: memory and cpu graphs of all servers, except servers 1 through 5. the entire month December\r\n* `targets dfs1 from noon+yesterday`: see all targets available for server dfs1\r\n* `diskspace_count type=byte_used mountpoint:_srv server:foo`: compare bytes used across all mountpoints matching '/srv' on all servers matching 'foo'.\r\n* `diskspace_rate type=byte_used mountpoint:_srv server:foo group by type`: similar, but compare the rate of change, and show graphs for each type (`bytes_free`, `inodes_used`, etc) so you can compare each server and/mountpoint.\r\n\r\n\r\n## Display of graphs:\r\n\r\n* all tags are displayed in a label whose color is deterministically computed from the name of the tag; they are also always printed in a consistent order\r\n  so that it's easy to discern what's what, and consistent throughout the entire app.\r\n* all tags that are constant for a graph (due to grouping by them, or because retrieved targets happen to share the same tag values) are shown as the graph title\r\n* the vertical title shows more info about the `<what>`, `<type>` and `<target_type>` in a more humanly readble form (\"/s\" for rate, \"/<interval>\" for counts, etc.\r\n* all tags that are variable across targets in a graph are shown as labels in the target legend. click on them to get more info about the metric (graphite metric name, found tags, etc)\r\n* in preferences.py you can define your count interval (statsd flushInterval) and graph options so that you can for example use binary prefixes instead of SI for diskspace/memory graphs;\r\n stacked graphs when displaying cpu states, etc.\r\n\r\n\r\n## Dependencies\r\n\r\n* python2: either 2.6 or higher, or 2.5 and the additional simplejson module\r\n\r\n## Installation\r\n\r\nJust get a code checkout and initialize all git submodules, like so:\r\n\r\n```\r\ngit clone --recursive https://github.com/vimeo/graph-explorer.git\r\n```\r\n\r\n## Configuration of graph-explorer\r\n\r\n```\r\n# inside the graph-explorer directory\r\n$EDITOR config.py\r\n# if you want annotated events using [anthracite](https://github.com/Dieterbe/anthracite) set `anthracite_url`\r\n# run update_metrics.py (protip: use cron), this downloads metrics.json and builds the enhanced metrics (tag datastructures).\r\n*/20 * * * * /path/to/graph-explorer/update_metrics.py &>/dev/null\r\n(note, if you have a lot of metrics, this can take a while. takes 5minutes on my 80k metrics)\r\n```\r\n\r\n## Configuration of graphite server\r\n\r\nyou'll need a small tweak to allow this app to request data from graphite.\r\nFor apache2 this works:\r\n\r\n    Header set Access-Control-Allow-Origin \"*\"\r\n    Header set Access-Control-Allow-Methods \"GET, OPTIONS\"\r\n    Header set Access-Control-Allow-Headers \"origin, authorization, accept\"\r\n\r\n## Running\r\n\r\n* default, with Paste (included):\r\n`./graph-explorer.py` and your page is available at `<ip>:8080`\r\n\r\n* alternatively, if you use gunicorn, you can run it with multi-workers like so:\r\n`gunicorn -w 4 app:'default_app()' -b 0.0.0.0:8080`\r\n\r\n\r\n## First steps\r\n\r\n* go to the debug page and see if any of metrics are being recognized.  You'll see tables of all tags found across your targets. and below that all enhanced metrics found.\r\n* if there's no metrics there, make sure you have a recent metrics.json file and plugins that have correct regular expressions that can match your metric names.  A good starting point is using statsd and the diamond monitoring agent.\r\n* start with a simple query like the name of a plugin or something you're sure will match something. example 'statsd' or 'plugin=statsd' or 'statsd count' etc.  the graph names and target names give you clues on other words you can use to filter.\r\n\r\n\r\n## Troubleshooting\r\n\r\n* no graphs show up and I don't know why.\r\n\r\nfirst check in the top section if there are target matching and 'total graphs' is > 0.  \r\nif not, your query expression might be too restricting.  or maybe it didn't find your metrics from metrics.json (see 'targets matching: x/total')  \r\nif yes, check for any errors in the javascript console, (in firefox you need firebug, in chrome and such 'tools->javascript console')\r\n\r\nalso check all network requests in the network tab, and make sure they return http 200 or 304\r\nespecially, check that the http requests to `graphite/render/?<...>` return actual data.\r\n(if not, there's something wrong with the request uri/targets.  you may be suffering from [this graphite bug](https://github.com/graphite-project/graphite-web/issues/289))\r\n\r\n* i get some error wrt graphite/apache cors access restriction\r\n\r\nsee section 'Configuration of graphite server' above\r\n\r\n\r\n## Writing your own plugins\r\n\r\nDefinitely read 'Enhanced Metrics' above, and preferrably the entire readme.\r\nA simple plugin such as diskspace.py is a good starting point.\r\nNotice:\r\n\r\n* targets is a list of rules (and 'subrules' under the 'targets' key which inherit from their parent)\r\n* the match regex must match a metric for it to yield an enhanced metric, all named groups will become tags\r\n* target_type must be one of the predefined values (see above)\r\n* one or more configurations can be applied, or override `default_configure_target` which always gets called\r\n  in these functions you can return a dict which'll get merged into your target (or just alter the target directly).\r\n  use this to change tags, the target, etc.\r\n\r\n`backend.update_data()` loads your metrics and gets matching targets and graphs by calling `list_targets(metrics)` and `list_graphs(metrics)` on a structured_metrics object.\r\n* the latter calls `list_graphs` on your plugin objects (this is for the statically defined graphs which you probably don't use).\r\n* `list_targets` goes over every metric, and for each goes over every plugin (ordered by priority), and\r\n  * calls `plugin_object.find_targets(metric)`, which goes over all target configs in the plugin and tries each out.\r\n  * each target config can have multiple match regexes. each can yield a target. (it gets created, sanitized, and the configure functions are run)\r\n  * each target config for which none of the no_match regexes matches, or the limit is reached, doesn't get yielded.\r\n  * first plugin that yields one or more targets wins for this metric (no other plugins are tried for that metric). that's why catchall plugins have lowest priority.\r\n\r\n\r\n## Getting in touch\r\n\r\n* irc: #monitoringlove on freenode (I'm there, Dieterbe)\r\n* or use github issues for bugs, feature requests, questions, feedback\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}